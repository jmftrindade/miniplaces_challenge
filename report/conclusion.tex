\section{Conclusion}

We find that single neural networks suffered from significant overfitting and none were able to achieve an accuracy above 77\% on the validation or test sets. We used several techniques to mitigate the drawbacks of these models including augmenting the training data with perturbations and changing the dropout keep probability to improve individual models. However even though this yielded small improvements, only ensembling techniques improved the accuracy significantly (over 80\%).

Had we more computational resources available, we would have liked to experiment with larger batch sizes, as well as stacking instead of bagging ensemble.